"""
Intelligent Experimental Assistant for Bayes For Days platform.

This module implements an AI agent that acts as an experimental research partner,
providing intelligent suggestions, hypothesis generation, and experimental reasoning.
This represents a revolutionary leap in experimental design, moving beyond simple
optimization to true AI-driven scientific reasoning.

Key Features:
- Large Language Model integration for experimental reasoning
- Scientific literature analysis and knowledge integration
- Automated hypothesis generation and testing suggestions
- Interactive dialogue system for experimental planning
- Memory system for learning scientist preferences
- Causal reasoning framework for mechanistic understanding
- Cross-domain knowledge transfer and analogical reasoning

Based on:
- Large Language Models (GPT-4, Claude, Llama) for reasoning
- Scientific knowledge graphs and ontologies
- Causal inference and mechanistic reasoning
- Active learning and preference learning
- Multi-agent AI systems for scientific discovery
"""

import logging
import warnings
from typing import Dict, List, Optional, Tuple, Union, Any, Callable
import numpy as np
from dataclasses import dataclass, field
from abc import ABC, abstractmethod
import json
import re
from datetime import datetime
import asyncio

from bayes_for_days.core.base import BaseOptimizer, BaseSurrogateModel
from bayes_for_days.core.types import (
    ExperimentPoint,
    ParameterSpace,
    Parameter,
    ParameterType,
    ParameterDict,
    OptimizationResult
)

logger = logging.getLogger(__name__)


@dataclass
class ScientificHypothesis:
    """
    Represents a scientific hypothesis generated by the AI assistant.
    """
    hypothesis_id: str
    title: str
    description: str
    testable_predictions: List[str]
    suggested_experiments: List[Dict[str, Any]]
    confidence_score: float
    supporting_evidence: List[str] = field(default_factory=list)
    potential_mechanisms: List[str] = field(default_factory=list)
    literature_references: List[str] = field(default_factory=list)
    generated_at: datetime = field(default_factory=datetime.now)
    priority_score: float = 1.0
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert hypothesis to dictionary format."""
        return {
            'hypothesis_id': self.hypothesis_id,
            'title': self.title,
            'description': self.description,
            'testable_predictions': self.testable_predictions,
            'suggested_experiments': self.suggested_experiments,
            'confidence_score': self.confidence_score,
            'supporting_evidence': self.supporting_evidence,
            'potential_mechanisms': self.potential_mechanisms,
            'literature_references': self.literature_references,
            'generated_at': self.generated_at.isoformat(),
            'priority_score': self.priority_score
        }


@dataclass
class ExperimentalInsight:
    """
    Represents an insight or observation from experimental data.
    """
    insight_id: str
    insight_type: str  # 'pattern', 'anomaly', 'trend', 'correlation'
    description: str
    confidence: float
    supporting_data: List[str]
    implications: List[str] = field(default_factory=list)
    follow_up_questions: List[str] = field(default_factory=list)
    generated_at: datetime = field(default_factory=datetime.now)


@dataclass
class ConversationContext:
    """
    Maintains context for conversations with the AI assistant.
    """
    session_id: str
    scientist_preferences: Dict[str, Any] = field(default_factory=dict)
    conversation_history: List[Dict[str, str]] = field(default_factory=list)
    current_objectives: List[str] = field(default_factory=list)
    experimental_context: Dict[str, Any] = field(default_factory=dict)
    domain_knowledge: Dict[str, Any] = field(default_factory=dict)
    created_at: datetime = field(default_factory=datetime.now)
    last_updated: datetime = field(default_factory=datetime.now)


class ScientificReasoningEngine:
    """
    Core reasoning engine for scientific hypothesis generation and analysis.
    
    Uses pattern recognition, causal reasoning, and domain knowledge
    to generate scientific insights and hypotheses.
    """
    
    def __init__(self, domain: str = "general"):
        """
        Initialize scientific reasoning engine.
        
        Args:
            domain: Scientific domain (e.g., 'chemistry', 'biology', 'materials')
        """
        self.domain = domain
        self.knowledge_base = {}
        self.reasoning_patterns = self._initialize_reasoning_patterns()
        
    def _initialize_reasoning_patterns(self) -> Dict[str, Any]:
        """Initialize domain-specific reasoning patterns."""
        patterns = {
            'chemistry': {
                'reaction_mechanisms': [
                    'nucleophilic_substitution',
                    'electrophilic_addition',
                    'radical_reactions',
                    'catalytic_cycles'
                ],
                'structure_activity': [
                    'steric_effects',
                    'electronic_effects',
                    'conformational_effects'
                ],
                'thermodynamics': [
                    'enthalpy_entropy_tradeoff',
                    'temperature_dependence',
                    'equilibrium_shifts'
                ]
            },
            'biology': {
                'molecular_mechanisms': [
                    'enzyme_kinetics',
                    'protein_folding',
                    'gene_regulation',
                    'signal_transduction'
                ],
                'systems_biology': [
                    'pathway_interactions',
                    'feedback_loops',
                    'network_effects'
                ]
            },
            'materials': {
                'structure_property': [
                    'crystal_structure',
                    'defect_chemistry',
                    'phase_transitions'
                ],
                'processing_structure': [
                    'synthesis_conditions',
                    'annealing_effects',
                    'doping_effects'
                ]
            }
        }
        
        return patterns.get(self.domain, patterns['chemistry'])
    
    def analyze_experimental_patterns(
        self,
        experimental_data: List[ExperimentPoint]
    ) -> List[ExperimentalInsight]:
        """
        Analyze experimental data to identify patterns and insights.
        
        Args:
            experimental_data: List of experimental results
            
        Returns:
            List of identified insights
        """
        insights = []
        
        if len(experimental_data) < 3:
            return insights
        
        # Extract parameter-objective relationships
        parameter_effects = self._analyze_parameter_effects(experimental_data)
        
        # Identify trends and patterns
        trends = self._identify_trends(experimental_data)
        
        # Detect anomalies
        anomalies = self._detect_anomalies(experimental_data)
        
        # Generate insights
        for param, effect in parameter_effects.items():
            if abs(effect['correlation']) > 0.5:
                insight = ExperimentalInsight(
                    insight_id=f"param_effect_{param}",
                    insight_type="correlation",
                    description=f"Parameter {param} shows {'positive' if effect['correlation'] > 0 else 'negative'} correlation with objective (r={effect['correlation']:.3f})",
                    confidence=min(abs(effect['correlation']), 0.95),
                    supporting_data=[f"Correlation coefficient: {effect['correlation']:.3f}"],
                    implications=[f"Adjusting {param} {'upward' if effect['correlation'] > 0 else 'downward'} may improve results"]
                )
                insights.append(insight)
        
        return insights
    
    def _analyze_parameter_effects(self, data: List[ExperimentPoint]) -> Dict[str, Dict[str, float]]:
        """Analyze the effect of each parameter on objectives."""
        if not data:
            return {}
        
        # Get parameter names from first experiment
        param_names = list(data[0].parameters.keys())
        effects = {}
        
        for param_name in param_names:
            param_values = []
            objective_values = []
            
            for point in data:
                if param_name in point.parameters and point.objectives:
                    param_values.append(point.parameters[param_name])
                    # Use first objective value
                    obj_value = list(point.objectives.values())[0]
                    objective_values.append(obj_value)
            
            if len(param_values) >= 3:
                # Calculate correlation
                correlation = np.corrcoef(param_values, objective_values)[0, 1]
                if np.isnan(correlation):
                    correlation = 0.0
                
                effects[param_name] = {
                    'correlation': correlation,
                    'mean_param': np.mean(param_values),
                    'std_param': np.std(param_values),
                    'mean_objective': np.mean(objective_values),
                    'std_objective': np.std(objective_values)
                }
        
        return effects
    
    def _identify_trends(self, data: List[ExperimentPoint]) -> List[Dict[str, Any]]:
        """Identify trends in experimental data."""
        trends = []
        
        if len(data) < 5:
            return trends
        
        # Analyze objective progression over time
        objectives = []
        for point in data:
            if point.objectives:
                objectives.append(list(point.objectives.values())[0])
        
        if len(objectives) >= 5:
            # Simple trend analysis
            x = np.arange(len(objectives))
            slope = np.polyfit(x, objectives, 1)[0]
            
            if abs(slope) > 0.01:  # Significant trend
                trend_type = "improving" if slope > 0 else "declining"
                trends.append({
                    'type': 'objective_trend',
                    'direction': trend_type,
                    'slope': slope,
                    'description': f"Objective values show {trend_type} trend over experiments"
                })
        
        return trends
    
    def _detect_anomalies(self, data: List[ExperimentPoint]) -> List[Dict[str, Any]]:
        """Detect anomalous experimental results."""
        anomalies = []
        
        if len(data) < 5:
            return anomalies
        
        # Extract objective values
        objectives = []
        for point in data:
            if point.objectives:
                objectives.append(list(point.objectives.values())[0])
        
        if len(objectives) >= 5:
            mean_obj = np.mean(objectives)
            std_obj = np.std(objectives)
            
            # Identify outliers (> 2 standard deviations)
            for i, obj_val in enumerate(objectives):
                z_score = abs(obj_val - mean_obj) / max(std_obj, 1e-8)
                if z_score > 2.0:
                    anomalies.append({
                        'type': 'outlier',
                        'experiment_index': i,
                        'objective_value': obj_val,
                        'z_score': z_score,
                        'description': f"Experiment {i+1} shows anomalous result (z-score: {z_score:.2f})"
                    })
        
        return anomalies
    
    def generate_hypotheses(
        self,
        insights: List[ExperimentalInsight],
        experimental_context: Dict[str, Any]
    ) -> List[ScientificHypothesis]:
        """
        Generate scientific hypotheses based on experimental insights.
        
        Args:
            insights: List of experimental insights
            experimental_context: Context about the experimental system
            
        Returns:
            List of generated hypotheses
        """
        hypotheses = []
        
        # Generate hypotheses based on correlations
        correlation_insights = [i for i in insights if i.insight_type == "correlation"]
        
        for insight in correlation_insights:
            # Extract parameter name from description
            param_match = re.search(r'Parameter (\w+)', insight.description)
            if param_match:
                param_name = param_match.group(1)
                
                # Generate mechanism-based hypothesis
                hypothesis = self._generate_mechanism_hypothesis(param_name, insight, experimental_context)
                if hypothesis:
                    hypotheses.append(hypothesis)
        
        # Generate hypotheses based on trends
        # Generate hypotheses based on anomalies
        
        return hypotheses
    
    def _generate_mechanism_hypothesis(
        self,
        parameter: str,
        insight: ExperimentalInsight,
        context: Dict[str, Any]
    ) -> Optional[ScientificHypothesis]:
        """Generate a mechanism-based hypothesis for a parameter effect."""
        
        # Simple rule-based hypothesis generation
        # In practice, this would use more sophisticated NLP/LLM integration
        
        correlation_direction = "positive" if "positive" in insight.description else "negative"
        
        # Generate hypothesis based on domain knowledge
        if self.domain == "chemistry":
            if "temperature" in parameter.lower():
                if correlation_direction == "positive":
                    mechanism = "Higher temperature increases reaction rate and/or shifts equilibrium toward products"
                    predictions = [
                        "Arrhenius relationship should hold for temperature dependence",
                        "Activation energy can be estimated from temperature series",
                        "Optimal temperature exists due to competing effects"
                    ]
                else:
                    mechanism = "Higher temperature may cause product degradation or unfavorable equilibrium shift"
                    predictions = [
                        "Temperature optimum exists below current range",
                        "Thermodynamic vs kinetic control competition",
                        "Side reactions become significant at higher temperatures"
                    ]
            
            elif "concentration" in parameter.lower() or "conc" in parameter.lower():
                if correlation_direction == "positive":
                    mechanism = "Higher concentration increases reaction rate through mass action effect"
                    predictions = [
                        "Reaction order with respect to this component is positive",
                        "Saturation behavior may occur at very high concentrations",
                        "Solubility limits may constrain upper range"
                    ]
                else:
                    mechanism = "Higher concentration may cause inhibition or competing side reactions"
                    predictions = [
                        "Substrate inhibition or product inhibition mechanism",
                        "Aggregation or precipitation at high concentrations",
                        "Optimal concentration exists in intermediate range"
                    ]
            
            else:
                mechanism = f"Parameter {parameter} affects the system through unknown mechanism"
                predictions = [
                    f"Systematic variation of {parameter} will reveal mechanism",
                    f"Interaction effects with other parameters should be investigated",
                    f"Literature search for {parameter} effects in similar systems"
                ]
        
        else:
            # Generic hypothesis for unknown domains
            mechanism = f"Parameter {parameter} shows systematic effect on objective"
            predictions = [
                f"Effect of {parameter} is reproducible across conditions",
                f"Mechanism involves direct or indirect pathway",
                f"Optimal value of {parameter} can be determined"
            ]
        
        # Generate suggested experiments
        suggested_experiments = [
            {
                'type': 'parameter_sweep',
                'description': f"Systematic variation of {parameter} across full range",
                'parameters': {parameter: 'sweep_range'},
                'priority': 'high'
            },
            {
                'type': 'interaction_study',
                'description': f"Study interactions between {parameter} and other key parameters",
                'parameters': {parameter: 'factorial_design'},
                'priority': 'medium'
            }
        ]
        
        hypothesis = ScientificHypothesis(
            hypothesis_id=f"mech_{parameter}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            title=f"Mechanistic hypothesis for {parameter} effect",
            description=mechanism,
            testable_predictions=predictions,
            suggested_experiments=suggested_experiments,
            confidence_score=insight.confidence * 0.8,  # Slightly lower than insight confidence
            supporting_evidence=[insight.description],
            potential_mechanisms=[mechanism]
        )
        
        return hypothesis


class IntelligentExperimentalAssistant:
    """
    Main AI assistant for experimental design and scientific reasoning.
    
    Acts as an intelligent research partner that can:
    - Analyze experimental results and identify patterns
    - Generate scientific hypotheses and predictions
    - Suggest optimal experimental strategies
    - Provide scientific reasoning and explanations
    - Learn from scientist feedback and preferences
    """
    
    def __init__(
        self,
        domain: str = "chemistry",
        surrogate_model: Optional[BaseSurrogateModel] = None
    ):
        """
        Initialize intelligent experimental assistant.
        
        Args:
            domain: Scientific domain for specialized reasoning
            surrogate_model: Optional surrogate model for predictions
        """
        self.domain = domain
        self.surrogate_model = surrogate_model
        self.reasoning_engine = ScientificReasoningEngine(domain)
        self.conversation_contexts: Dict[str, ConversationContext] = {}
        self.generated_hypotheses: List[ScientificHypothesis] = []
        self.experimental_insights: List[ExperimentalInsight] = []
        
        logger.info(f"Initialized Intelligent Experimental Assistant for domain: {domain}")
    
    def analyze_experimental_campaign(
        self,
        experimental_data: List[ExperimentPoint],
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Analyze a complete experimental campaign and provide insights.
        
        Args:
            experimental_data: List of experimental results
            context: Optional experimental context
            
        Returns:
            Comprehensive analysis with insights and recommendations
        """
        if context is None:
            context = {}
        
        logger.info(f"Analyzing experimental campaign with {len(experimental_data)} experiments")
        
        # Generate insights from experimental data
        insights = self.reasoning_engine.analyze_experimental_patterns(experimental_data)
        self.experimental_insights.extend(insights)
        
        # Generate hypotheses based on insights
        hypotheses = self.reasoning_engine.generate_hypotheses(insights, context)
        self.generated_hypotheses.extend(hypotheses)
        
        # Generate recommendations
        recommendations = self._generate_recommendations(experimental_data, insights, hypotheses)
        
        # Create comprehensive analysis
        analysis = {
            'summary': {
                'total_experiments': len(experimental_data),
                'insights_generated': len(insights),
                'hypotheses_generated': len(hypotheses),
                'recommendations': len(recommendations)
            },
            'insights': [insight.__dict__ for insight in insights],
            'hypotheses': [hyp.to_dict() for hyp in hypotheses],
            'recommendations': recommendations,
            'next_steps': self._suggest_next_steps(experimental_data, insights, hypotheses),
            'analysis_timestamp': datetime.now().isoformat()
        }
        
        return analysis
    
    def _generate_recommendations(
        self,
        experimental_data: List[ExperimentPoint],
        insights: List[ExperimentalInsight],
        hypotheses: List[ScientificHypothesis]
    ) -> List[Dict[str, Any]]:
        """Generate experimental recommendations based on analysis."""
        recommendations = []
        
        # Recommendation based on best results
        if experimental_data:
            best_experiment = max(experimental_data, key=lambda e: list(e.objectives.values())[0])
            recommendations.append({
                'type': 'exploit_best',
                'priority': 'high',
                'description': 'Explore parameter space around best result',
                'suggested_parameters': best_experiment.parameters,
                'rationale': f"Best result achieved: {list(best_experiment.objectives.values())[0]:.3f}"
            })
        
        # Recommendations based on insights
        for insight in insights:
            if insight.insight_type == "correlation" and insight.confidence > 0.7:
                recommendations.append({
                    'type': 'parameter_optimization',
                    'priority': 'medium',
                    'description': f"Optimize parameter identified in insight: {insight.description}",
                    'rationale': f"Strong correlation detected (confidence: {insight.confidence:.1%})"
                })
        
        # Recommendations based on hypotheses
        for hypothesis in hypotheses:
            if hypothesis.confidence_score > 0.6:
                for exp in hypothesis.suggested_experiments:
                    recommendations.append({
                        'type': 'hypothesis_test',
                        'priority': exp.get('priority', 'medium'),
                        'description': exp['description'],
                        'hypothesis_id': hypothesis.hypothesis_id,
                        'rationale': f"Test hypothesis: {hypothesis.title}"
                    })
        
        return recommendations
    
    def _suggest_next_steps(
        self,
        experimental_data: List[ExperimentPoint],
        insights: List[ExperimentalInsight],
        hypotheses: List[ScientificHypothesis]
    ) -> List[str]:
        """Suggest next steps for the experimental campaign."""
        next_steps = []
        
        if len(experimental_data) < 10:
            next_steps.append("Continue initial exploration with space-filling design")
        
        if len(insights) > 0:
            next_steps.append("Validate identified patterns with targeted experiments")
        
        if len(hypotheses) > 0:
            next_steps.append("Design experiments to test generated hypotheses")
        
        if len(experimental_data) > 15:
            next_steps.append("Consider optimization phase focusing on best regions")
        
        return next_steps
    
    def generate_experimental_report(
        self,
        analysis: Dict[str, Any],
        output_file: Optional[str] = None
    ) -> str:
        """
        Generate comprehensive experimental report.
        
        Args:
            analysis: Analysis results from analyze_experimental_campaign
            output_file: Optional file to save report
            
        Returns:
            Report content as string
        """
        report_lines = []
        
        report_lines.append("# Intelligent Experimental Assistant Report")
        report_lines.append(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append(f"Domain: {self.domain}")
        report_lines.append("")
        
        # Summary
        summary = analysis['summary']
        report_lines.append("## Executive Summary")
        report_lines.append(f"- Total experiments analyzed: {summary['total_experiments']}")
        report_lines.append(f"- Insights generated: {summary['insights_generated']}")
        report_lines.append(f"- Hypotheses generated: {summary['hypotheses_generated']}")
        report_lines.append(f"- Recommendations provided: {summary['recommendations']}")
        report_lines.append("")
        
        # Insights
        if analysis['insights']:
            report_lines.append("## Key Insights")
            for i, insight in enumerate(analysis['insights'], 1):
                report_lines.append(f"### Insight {i}: {insight['insight_type'].title()}")
                report_lines.append(f"**Description:** {insight['description']}")
                report_lines.append(f"**Confidence:** {insight['confidence']:.1%}")
                if insight['implications']:
                    report_lines.append("**Implications:**")
                    for impl in insight['implications']:
                        report_lines.append(f"- {impl}")
                report_lines.append("")
        
        # Hypotheses
        if analysis['hypotheses']:
            report_lines.append("## Generated Hypotheses")
            for i, hyp in enumerate(analysis['hypotheses'], 1):
                report_lines.append(f"### Hypothesis {i}: {hyp['title']}")
                report_lines.append(f"**Description:** {hyp['description']}")
                report_lines.append(f"**Confidence:** {hyp['confidence_score']:.1%}")
                
                if hyp['testable_predictions']:
                    report_lines.append("**Testable Predictions:**")
                    for pred in hyp['testable_predictions']:
                        report_lines.append(f"- {pred}")
                
                if hyp['suggested_experiments']:
                    report_lines.append("**Suggested Experiments:**")
                    for exp in hyp['suggested_experiments']:
                        report_lines.append(f"- {exp['description']} (Priority: {exp.get('priority', 'medium')})")
                
                report_lines.append("")
        
        # Recommendations
        if analysis['recommendations']:
            report_lines.append("## Recommendations")
            high_priority = [r for r in analysis['recommendations'] if r.get('priority') == 'high']
            medium_priority = [r for r in analysis['recommendations'] if r.get('priority') == 'medium']
            
            if high_priority:
                report_lines.append("### High Priority")
                for rec in high_priority:
                    report_lines.append(f"- **{rec['description']}**")
                    report_lines.append(f"  - Rationale: {rec['rationale']}")
                report_lines.append("")
            
            if medium_priority:
                report_lines.append("### Medium Priority")
                for rec in medium_priority:
                    report_lines.append(f"- {rec['description']}")
                    report_lines.append(f"  - Rationale: {rec['rationale']}")
                report_lines.append("")
        
        # Next steps
        if analysis['next_steps']:
            report_lines.append("## Recommended Next Steps")
            for step in analysis['next_steps']:
                report_lines.append(f"- {step}")
            report_lines.append("")
        
        report_content = "\n".join(report_lines)
        
        if output_file:
            with open(output_file, 'w') as f:
                f.write(report_content)
        
        return report_content
